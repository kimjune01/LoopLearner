# LLM Provider Configuration
# Options: "ollama", "openai", "anthropic", "mock"
LLM_PROVIDER=ollama

# Model Configuration
LLM_MODEL=llama3.2:3b
# For OpenAI: gpt-4, gpt-3.5-turbo
# For Anthropic: claude-3-sonnet-20240229

# API Configuration (for remote providers)
LLM_API_KEY=your-api-key-here
LLM_BASE_URL=localhost:11434

# Generation Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500

# Django Configuration
DEBUG=True
SECRET_KEY=your-secret-key-here